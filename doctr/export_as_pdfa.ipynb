{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ID2g9XHMvAXO"
   },
   "source": [
    "# Generate PDF/A files from docTR output\n",
    "\n",
    "These files have also a readable text layer on top of the image, which can be used to search in a document with any PDF-Viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPMz5UYUvAXQ",
    "outputId": "6b4284e0-0efe-4443-911b-840e90145716"
   },
   "outputs": [],
   "source": [
    "# Colab related installations to install pyproject.toml projects correctly\n",
    "!sudo apt install libcairo2-dev pkg-config\n",
    "!pip3 install pycairo\n",
    "# Install doctr\n",
    "!pip3 install python-doctr[tf,viz]@git+https://github.com/mindee/doctr.git\n",
    "!pip3 install reportlab>=3.6.2\n",
    "# Optional if you want to merge multiple pdfs\n",
    "!pip3 install PyPDF2==1.26.0\n",
    "# Restart runtime\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZC8sIbEZvAXS"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import base64\n",
    "import re\n",
    "from tempfile import TemporaryDirectory\n",
    "from math import atan, cos, sin\n",
    "from typing import Dict, Optional, Tuple\n",
    "from xml.etree import ElementTree as ET\n",
    "from xml.etree.ElementTree import Element\n",
    "\n",
    "import numpy as np\n",
    "import PyPDF2\n",
    "from PyPDF2 import PdfFileMerger\n",
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor\n",
    "from PIL import Image\n",
    "from reportlab.lib.colors import black\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.lib.utils import ImageReader\n",
    "from reportlab.pdfgen.canvas import Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aa9PoeOdvAXS"
   },
   "source": [
    "## Define the hOCR (xml) parser\n",
    "At the beginning, we have to define a HocrParser which is able to parse the exported XML-Tree/File.\n",
    "\n",
    "[hOCR convention](https://github.com/kba/hocr-spec/blob/master/1.2/spec.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pblMOnCovAXT"
   },
   "outputs": [],
   "source": [
    "class HocrParser():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.box_pattern = re.compile(r'bbox((\\s+\\d+){4})')\n",
    "        self.baseline_pattern = re.compile(r'baseline((\\s+[\\d\\.\\-]+){2})')\n",
    "\n",
    "    def _element_coordinates(self, element: Element) -> Dict:\n",
    "        \"\"\"\n",
    "        Returns a tuple containing the coordinates of the bounding box around\n",
    "        an element\n",
    "        \"\"\"\n",
    "        out = out = {'x1': 0, 'y1': 0, 'x2': 0, 'y2': 0}\n",
    "        if 'title' in element.attrib:\n",
    "            matches = self.box_pattern.search(element.attrib['title'])\n",
    "            if matches:\n",
    "                coords = matches.group(1).split()\n",
    "                out = {'x1': int(coords[0]), 'y1': int(\n",
    "                    coords[1]), 'x2': int(coords[2]), 'y2': int(coords[3])}\n",
    "        return out\n",
    "\n",
    "    def _get_baseline(self, element: Element) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Returns a tuple containing the baseline slope and intercept.\n",
    "        \"\"\"\n",
    "        if 'title' in element.attrib:\n",
    "            matches = self.baseline_pattern.search(\n",
    "                element.attrib['title']).group(1).split()\n",
    "            if matches:\n",
    "                return float(matches[0]), float(matches[1])\n",
    "        return (0.0, 0.0)\n",
    "\n",
    "    def _pt_from_pixel(self, pxl: Dict, dpi: int) -> Dict:\n",
    "        \"\"\"\n",
    "        Returns the quantity in PDF units (pt) given quantity in pixels\n",
    "        \"\"\"\n",
    "        pt = [(c / dpi * inch) for c in pxl.values()]\n",
    "        return {'x1': pt[0], 'y1': pt[1], 'x2': pt[2], 'y2': pt[3]}\n",
    "\n",
    "    def _get_element_text(self, element: Element) -> str:\n",
    "        \"\"\"\n",
    "        Return the textual content of the element and its children\n",
    "        \"\"\"\n",
    "        text = ''\n",
    "        if element.text is not None:\n",
    "            text += element.text\n",
    "        for child in element:\n",
    "            text += self._get_element_text(child)\n",
    "        if element.tail is not None:\n",
    "            text += element.tail\n",
    "        return text\n",
    "\n",
    "    def export_pdfa(self,\n",
    "                    out_filename: str,\n",
    "                    hocr: ET.ElementTree,\n",
    "                    image: Optional[np.ndarray] = None,\n",
    "                    fontname: str = \"Times-Roman\",\n",
    "                    fontsize: int = 12,\n",
    "                    invisible_text: bool = True,\n",
    "                    add_spaces: bool = True,\n",
    "                    dpi: int = 300):\n",
    "        \"\"\"\n",
    "        Generates a PDF/A document from a hOCR document.\n",
    "        \"\"\"\n",
    "\n",
    "        width, height = None, None\n",
    "        # Get the image dimensions\n",
    "        for div in hocr.findall(\".//div[@class='ocr_page']\"):\n",
    "            coords = self._element_coordinates(div)\n",
    "            pt_coords = self._pt_from_pixel(coords, dpi)\n",
    "            width, height = pt_coords['x2'] - \\\n",
    "                pt_coords['x1'], pt_coords['y2'] - pt_coords['y1']\n",
    "            # after catch break loop\n",
    "            break\n",
    "        if width is None or height is None:\n",
    "            raise ValueError(\"Could not determine page size\")\n",
    "\n",
    "        pdf = Canvas(out_filename, pagesize=(width, height), pageCompression=1)\n",
    "\n",
    "        span_elements = [element for element in hocr.iterfind(\".//span\")]\n",
    "        for line in span_elements:\n",
    "            if 'class' in line.attrib and line.attrib['class'] == 'ocr_line' and line is not None:\n",
    "                # get information from xml\n",
    "                pxl_line_coords = self._element_coordinates(line)\n",
    "                line_box = self._pt_from_pixel(pxl_line_coords, dpi)\n",
    "\n",
    "                # compute baseline\n",
    "                slope, pxl_intercept = self._get_baseline(line)\n",
    "                if abs(slope) < 0.005:\n",
    "                    slope = 0.0\n",
    "                angle = atan(slope)\n",
    "                cos_a, sin_a = cos(angle), sin(angle)\n",
    "                intercept = pxl_intercept / dpi * inch\n",
    "                baseline_y2 = height - (line_box['y2'] + intercept)\n",
    "\n",
    "                # configure options\n",
    "                text = pdf.beginText()\n",
    "                text.setFont(fontname, fontsize)\n",
    "                pdf.setFillColor(black)\n",
    "                if invisible_text:\n",
    "                    text.setTextRenderMode(3)  # invisible text\n",
    "\n",
    "                # transform overlayed text\n",
    "                text.setTextTransform(\n",
    "                    cos_a, -sin_a, sin_a, cos_a, line_box['x1'], baseline_y2)\n",
    "\n",
    "                elements = line.findall(\".//span[@class='ocrx_word']\")\n",
    "                for elem in elements:\n",
    "                    elemtxt = self._get_element_text(elem).strip()\n",
    "                    # replace unsupported characters\n",
    "                    elemtxt = elemtxt.translate(str.maketrans(\n",
    "                        {'ﬀ': 'ff', 'ﬃ': 'f‌f‌i', 'ﬄ': 'f‌f‌l', 'ﬁ': 'fi', 'ﬂ': 'fl'}))\n",
    "                    if not elemtxt:\n",
    "                        continue\n",
    "\n",
    "                    # compute string width\n",
    "                    pxl_coords = self._element_coordinates(elem)\n",
    "                    box = self._pt_from_pixel(pxl_coords, dpi)\n",
    "                    if add_spaces:\n",
    "                        elemtxt += ' '\n",
    "                        box_width = box['x2'] + pdf.stringWidth(elemtxt, fontname, fontsize) - box['x1']\n",
    "                    else:\n",
    "                        box_width = box['x2'] - box['x1']\n",
    "                    font_width = pdf.stringWidth(elemtxt, fontname, fontsize)\n",
    "\n",
    "                    # Adjust relative position of cursor\n",
    "                    cursor = text.getStartOfLine()\n",
    "                    dx = box['x1'] - cursor[0]\n",
    "                    dy = baseline_y2 - cursor[1]\n",
    "                    text.moveCursor(dx, dy)\n",
    "\n",
    "                    # suppress text if it is 0 units wide\n",
    "                    if font_width > 0:\n",
    "                        text.setHorizScale(100 * box_width / font_width)\n",
    "                        text.textOut(elemtxt)\n",
    "                pdf.drawText(text)\n",
    "\n",
    "        # overlay image if provided\n",
    "        if image is not None:\n",
    "            pdf.drawImage(ImageReader(Image.fromarray(image)),\n",
    "                          0, 0, width=width, height=height)\n",
    "        pdf.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzpt5nHFvAXe"
   },
   "source": [
    "## OCR the files and show the results\n",
    "\n",
    "Now we are ready to start the OCR process and show the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HjhRaZ6tvAXe"
   },
   "outputs": [],
   "source": [
    "# Download a sample\n",
    "!wget https://www.allianzdirect.de/dam/documents/home/Versicherungsbedingungen-08-2021.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file\n",
    "docs = DocumentFile.from_pdf(\"Versicherungsbedingungen-08-2021.pdf\")\n",
    "model = ocr_predictor(det_arch='db_resnet50', reco_arch='crnn_vgg16_bn', pretrained=True)\n",
    "# we will grab only the first two pages from the pdf for demonstration\n",
    "result = model(docs[:2])\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MiA8N21GvAXf"
   },
   "source": [
    "## Export as PDF/A \n",
    "In this section we will export our documents as PDF/A files.\n",
    "\n",
    "We show 3 possible options for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All as single PDF/A file\n",
    "All files will be saved as single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dDy5t1UvAXf"
   },
   "outputs": [],
   "source": [
    "# returns: list of tuple where the first element is the (bytes) xml string and the second is the ElementTree\n",
    "xml_outputs = result.export_as_xml()\n",
    "\n",
    "# init the above parser\n",
    "parser = HocrParser()\n",
    "\n",
    "# iterate through the xml outputs and images and export to pdf/a\n",
    "# the image is optional else you can set invisible_text=False and the text will be printed on a blank page\n",
    "for i, (xml, img) in enumerate(zip(xml_outputs, docs)):\n",
    "    xml_element_tree = xml[1]\n",
    "    parser.export_pdfa(f'{i}.pdf', hocr=xml_element_tree, image=img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All merged into one PDF/A file\n",
    "All PDF/A files will be merged into one PDF/A file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SkEZrL-hvAXg"
   },
   "outputs": [],
   "source": [
    "# returns: list of tuple where the first element is the (bytes) xml string and the second is the ElementTree\n",
    "xml_outputs = result.export_as_xml()\n",
    "\n",
    "# init the above parser\n",
    "parser = HocrParser()\n",
    "\n",
    "# you can also merge multiple pdfs into one\n",
    "\n",
    "merger = PdfFileMerger()\n",
    "for i, (xml, img) in enumerate(zip(xml_outputs, docs)):\n",
    "    xml_element_tree = xml[1]\n",
    "    with TemporaryDirectory() as tmpdir:\n",
    "        parser.export_pdfa(f'{tmpdir}/{i}.pdf', hocr=xml_element_tree, image=img)\n",
    "        merger.append(f'{tmpdir}/{i}.pdf')\n",
    "merger.write(f'docTR-PDF.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All as base64 encoded PDF/A files\n",
    "All PDF/A files will be saved as base64 strings in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owWVIPcKvAXg",
    "outputId": "ad9b4eda-146b-4ab1-c613-06af4afce64b"
   },
   "outputs": [],
   "source": [
    "# returns: list of tuple where the first element is the (bytes) xml string and the second is the ElementTree\n",
    "xml_outputs = result.export_as_xml()\n",
    "\n",
    "# init the above parser\n",
    "parser = HocrParser()\n",
    "\n",
    "# or encode the pdfs into base64 (Rest API usage)\n",
    "\n",
    "base64_encoded_pdfs = list()\n",
    "for i, (xml, img) in enumerate(zip(xml_outputs, docs)):\n",
    "    xml_element_tree = xml[1]\n",
    "    with TemporaryDirectory() as tmpdir:\n",
    "        parser.export_pdfa(f'{tmpdir}/{i}.pdf',\n",
    "                           hocr=xml_element_tree, image=img)\n",
    "        with open(f'{tmpdir}/{i}.pdf', 'rb') as f:\n",
    "            base64_encoded_pdfs.append(base64.b64encode(f.read()))\n",
    "print(f'{len(base64_encoded_pdfs)} pdfs encoded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can I use a PDF/A?\n",
    "You can open the saved pdf's with any PDF-Viewer and type some words you are searching for in the document.\n",
    "\n",
    "Matches will be highlighted in the text layer.\n",
    "\n",
    "Or you use Python to search, for example words in the text layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search specific words in the pdf and print all matches\n",
    "pattern = \"Allianz\"\n",
    "file_name = \"docTR-PDF.pdf\"\n",
    "\n",
    "reader = PyPDF2.PdfFileReader(file_name)\n",
    "num_pages = reader.getNumPages()\n",
    "\n",
    "for i in range(0, num_pages):\n",
    "    page = reader.getPage(i)\n",
    "    text = page.extractText()\n",
    "    \n",
    "    for match in re.finditer(pattern, text):\n",
    "        print(f'Page no: {i} | Match: {match}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To go further\n",
    "[Wikipedia PDF/A](https://en.wikipedia.org/wiki/PDF/A)\n",
    "\n",
    "[Difference between PDF/A and PDF](https://askanydifference.com/difference-between-pdf-a-and-pdf/)\n",
    "\n",
    "### Happy Coding :)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "generate_pdfa_from_doctr_output.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "103ff19777622dbbd1c8370264e2f56c4c49c75e119dc12fd0a9f41eba03d66f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
